{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "8HJDmBvPkFx7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XOR Data\n",
        "x_seeds = np.array([(0,0), (1,0), (0,1), (1,1)], dtype = np.float64)\n",
        "y_seeds = np.array([0,1,1,0])"
      ],
      "metadata": {
        "id": "qg7PYx4Qo9CI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 1000\n",
        "idxs = np.random.randint(0,4,N)"
      ],
      "metadata": {
        "id": "WUQrXGlesy9A"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = x_seeds[idxs]\n",
        "Y = y_seeds[idxs]"
      ],
      "metadata": {
        "id": "-SYKTii9s4_e"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X += np.random.normal(scale = 0.25, size = X.shape)"
      ],
      "metadata": {
        "id": "EXEOfOC2s9JC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class shallow_neural_network():\n",
        "    def __init__(self, num_input_features, num_hiddens):\n",
        "        self.num_input_features = num_input_features\n",
        "        self.num_hiddens = num_hiddens\n",
        "\n",
        "        self.W1 = np.random.normal(size=(num_hiddens, num_input_features))\n",
        "        self.b1 = np.random.normal(size=num_hiddens)\n",
        "        self.W2 = np.random.normal(size=num_hiddens)\n",
        "        self.b2 = np.random.normal(size=1)\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def predict(self, x):\n",
        "        z1 = np.matmul(self.W1, x) + self.b1\n",
        "        a1 = np.tanh(z1)\n",
        "        z2 = np.matmul(self.W2, a1) + self.b2\n",
        "        a2 = self.sigmoid(z2)\n",
        "        return a2, (z1, a1, z2, a2)\n"
      ],
      "metadata": {
        "id": "o4ZcfULftD5h"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = shallow_neural_network(2,3)"
      ],
      "metadata": {
        "id": "I50ylOckKrbE"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 train 모델 (Vector 계산 없음)\n",
        "def train1(X, Y, model, lr=0.1):\n",
        "  \"\"\"\n",
        "  신경망 모델을 훈련하는 함수\n",
        "\n",
        "  Args:\n",
        "    X: 입력 데이터 (numpy 배열)\n",
        "    Y: 레이블 데이터 (numpy 배열)\n",
        "    model: 훈련할 신경망 모델 객체\n",
        "    lr: 학습률 (기본값: 0.1)\n",
        "\n",
        "  Returns:\n",
        "    훈련 후의 손실 값\n",
        "  \"\"\"\n",
        "\n",
        "  # 모델의 가중치 및 편향과 동일한 모양의 0으로 채워진 배열 초기화\n",
        "  dW1 = np.zeros_like(model.W1)\n",
        "  db1 = np.zeros_like(model.b1)\n",
        "  dW2 = np.zeros_like(model.W2)\n",
        "  db2 = np.zeros_like(model.b2)\n",
        "\n",
        "  m = len(X)  # 데이터 샘플 수\n",
        "  cost = 0.0  # 손실 초기화\n",
        "\n",
        "  # 각 데이터 샘플에 대해 반복\n",
        "  for x, y in zip(X, Y):\n",
        "    # 모델 예측\n",
        "    a2, (z1, a1, z2, _) = model.predict(x)\n",
        "\n",
        "    # 손실 계산 (이진 교차 엔트로피)\n",
        "    if y == 1:\n",
        "      cost -= np.log(a2)\n",
        "    else:\n",
        "      cost -= np.log(1 - a2)\n",
        "\n",
        "    # 출력층 오차 계산\n",
        "    diff = a2 - y\n",
        "\n",
        "    # 출력층 가중치 및 편향 업데이트\n",
        "    db2 += diff\n",
        "\n",
        "    for i in range(model.num_hiddens):\n",
        "      dW2[i] += a1[i] * diff\n",
        "\n",
        "    # 은닉층 오차 계산 및 가중치 및 편향 업데이트\n",
        "    for i in range(model.num_hiddens):\n",
        "      db1[i] += (1 - a1[i]**2) * model.W2[i] * diff\n",
        "    for i in range(model.num_hiddens):\n",
        "      for j in range(model.num_input_features):\n",
        "        dW1[i, j] += x[j] * (1 - a1[i]**2) * model.W2[i] * diff\n",
        "\n",
        "  # 평균 손실 계산\n",
        "  cost /= m\n",
        "\n",
        "  # 가중치 및 편향 업데이트\n",
        "  model.W1 -= lr * dW1 / m\n",
        "  model.b1 -= lr * db1 / m\n",
        "  model.W2 -= lr * dW2 / m\n",
        "  model.b2 -= lr * db2 / m\n",
        "\n",
        "  return cost"
      ],
      "metadata": {
        "id": "vtMm3I9nohWZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 변경된 train 모델 (Vector 계산 있음)\n",
        "def train2(X, Y, model, lr=0.1):\n",
        "    \"\"\"\n",
        "    신경망 모델을 훈련하는 함수\n",
        "\n",
        "    Args:\n",
        "        X: 입력 데이터 (numpy 배열)\n",
        "        Y: 레이블 데이터 (numpy 배열)\n",
        "        model: 훈련할 신경망 모델 객체\n",
        "        lr: 학습률 (기본값: 0.1)\n",
        "\n",
        "    Returns:\n",
        "        훈련 후의 손실 값\n",
        "    \"\"\"\n",
        "\n",
        "    # 모델의 가중치 및 편향과 동일한 모양의 0으로 채워진 배열 초기화\n",
        "    dW1 = np.zeros_like(model.W1)\n",
        "    db1 = np.zeros_like(model.b1)\n",
        "    dW2 = np.zeros_like(model.W2)\n",
        "    db2 = np.zeros_like(model.b2)\n",
        "\n",
        "    m = len(X)  # 데이터 샘플 수\n",
        "    cost = 0.0  # 손실 초기화\n",
        "\n",
        "    # 순전파 및 역전파\n",
        "    for x, y in zip(X, Y):\n",
        "        # 모델 예측\n",
        "        a2, (z1, a1, z2, _) = model.predict(x)\n",
        "\n",
        "        # 손실 계산 (이진 교차 엔트로피)\n",
        "        cost -= np.log(a2) if y == 1 else np.log(1 - a2)\n",
        "\n",
        "        # 출력층 오차 계산\n",
        "        diff = a2 - y\n",
        "\n",
        "        # 출력층 가중치 및 편향 업데이트 (벡터 연산 적용)\n",
        "        db2 += diff\n",
        "        dW2 += np.outer(a1, diff).reshape(dW2.shape)  # a1 * diff의 벡터 연산\n",
        "\n",
        "        # 은닉층 오차 계산 및 가중치 및 편향 업데이트 (벡터 연산 적용)\n",
        "        delta1 = (1 - a1**2) * model.W2 * diff  # 은닉층 오차 계산\n",
        "        db1 += delta1\n",
        "        dW1 += np.outer(delta1, x)  # x * delta1의 벡터 연산\n",
        "\n",
        "    # 평균 손실 계산\n",
        "    cost /= m\n",
        "\n",
        "    # 가중치 및 편향 업데이트\n",
        "    model.W1 -= lr * dW1 / m\n",
        "    model.b1 -= lr * db1 / m\n",
        "    model.W2 -= lr * dW2 / m\n",
        "    model.b2 -= lr * db2 / m\n",
        "\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "KvOb5R__FUv4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "  cost = train2(X,Y, model, 1.0)\n",
        "  if epoch % 10 == 0:\n",
        "    print(epoch, cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMqjjjYFItzm",
        "outputId": "8d42c943-f79a-42ae-ac46-671bf76a62f5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [1.18064132]\n",
            "10 [0.65943083]\n",
            "20 [0.62982477]\n",
            "30 [0.59894456]\n",
            "40 [0.56832475]\n",
            "50 [0.54099461]\n",
            "60 [0.5178652]\n",
            "70 [0.49821815]\n",
            "80 [0.48013423]\n",
            "90 [0.45871102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict((0,0))[0].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8Ta-6aRTVPo",
        "outputId": "51c3ec37-b568-46a2-8a2b-0a16711c48bb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4578090594042799"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict((0,1))[0].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbidaxRIWBy0",
        "outputId": "0084f7f5-47b6-47be-b7df-68c8a1aee11e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5438960869513847"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict((1,0))[0].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErmKjc5SWBpT",
        "outputId": "d8adbcfb-b30a-4d8d-be83-3b50a005db87"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.92166610869742"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict((1,1))[0].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3DmhwYUWBZE",
        "outputId": "235baa3c-d1c8-4cf9-ba92-3ae60c5ad1f9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0926880560374332"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}